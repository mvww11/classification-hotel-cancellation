{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelagem\n",
    "Após terminar a Análise Exploratória de Dados e o Feature Engineering, feitos no arquivo [EDA.ipynb](EDA.ipynb), vamos iniciar o treinamento de nosso modelo. O objetivo do modelo é prever se uma reserva será cancelada.\n",
    "\n",
    "Utilizaremos o algoritmo XGBoost, que é uma implementação otimizada de Gradient Boosting. O Gradient Boosting é um algoritmo de ensemble no qual treinamos classificadores de forma sequencial, em que cada classificador tenta corrigir os erros dos anteriores por meio da modalagem dos resíduos deixados por eles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carregando as bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix, classification_report, f1_score, plot_roc_curve\n",
    "\n",
    "\n",
    "#carregando os dados\n",
    "df = pd.read_csv('hotels_model_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#os meses de ArrivalDateMonth estãocomo string.\n",
    "print(df.ArrivalDateMonth.unique())\n",
    "\n",
    "#convertendo os meses para números (para não trabalhar com 12 dummies)\n",
    "df.ArrivalDateMonth = df.ArrivalDateMonth.map({'January': 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June': 6, 'July': 7, 'August': 8, 'September': 9, 'October': 10, 'November': 11, 'December': 12})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessamento das features\n",
    "Antes do treinamento, faremos um preprocessamento final das features. Vamos transformar as features categórias em dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertendo a quantidade de Children para int (estão em float)\n",
    "df.Children = df.Children.apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#substituindo os 'espaços' por '_' nas categorias de DepositType\n",
    "df.DepositType = df.DepositType.map({'No Deposit': 'No_Deposit', 'Non Refund': 'Non_Refund', 'Refundable': 'Refundable'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gerando as colunas dummies das features categóricas\n",
    "df_model = pd.get_dummies(df, columns=['ArrivalDateMonth', 'Meal', 'MarketSegment', 'DistributionChannel', 'ReservedRoomType', 'DepositType', 'CustomerType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 78879 entries, 0 to 78878\n",
      "Data columns (total 61 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   IsCanceled                     78879 non-null  int64  \n",
      " 1   LeadTime                       78879 non-null  int64  \n",
      " 2   ArrivalDateWeekNumber          78879 non-null  int64  \n",
      " 3   ArrivalDateDayOfMonth          78879 non-null  int64  \n",
      " 4   StaysInWeekendNights           78879 non-null  int64  \n",
      " 5   StaysInWeekNights              78879 non-null  int64  \n",
      " 6   Adults                         78879 non-null  int64  \n",
      " 7   Children                       78879 non-null  int64  \n",
      " 8   Babies                         78879 non-null  int64  \n",
      " 9   IsRepeatedGuest                78879 non-null  int64  \n",
      " 10  PreviousCancellations          78879 non-null  int64  \n",
      " 11  PreviousBookingsNotCanceled    78879 non-null  int64  \n",
      " 12  BookingChanges                 78879 non-null  int64  \n",
      " 13  ADR                            78879 non-null  float64\n",
      " 14  RequiredCarParkingSpaces       78879 non-null  int64  \n",
      " 15  TotalOfSpecialRequests         78879 non-null  int64  \n",
      " 16  isOnlyWeekend                  78879 non-null  int64  \n",
      " 17  isEU                           78879 non-null  int64  \n",
      " 18  isPRT                          78879 non-null  int64  \n",
      " 19  Agent_top                      78879 non-null  int64  \n",
      " 20  ArrivalDateMonth_April         78879 non-null  uint8  \n",
      " 21  ArrivalDateMonth_August        78879 non-null  uint8  \n",
      " 22  ArrivalDateMonth_December      78879 non-null  uint8  \n",
      " 23  ArrivalDateMonth_February      78879 non-null  uint8  \n",
      " 24  ArrivalDateMonth_January       78879 non-null  uint8  \n",
      " 25  ArrivalDateMonth_July          78879 non-null  uint8  \n",
      " 26  ArrivalDateMonth_June          78879 non-null  uint8  \n",
      " 27  ArrivalDateMonth_March         78879 non-null  uint8  \n",
      " 28  ArrivalDateMonth_May           78879 non-null  uint8  \n",
      " 29  ArrivalDateMonth_November      78879 non-null  uint8  \n",
      " 30  ArrivalDateMonth_October       78879 non-null  uint8  \n",
      " 31  ArrivalDateMonth_September     78879 non-null  uint8  \n",
      " 32  Meal_BB                        78879 non-null  uint8  \n",
      " 33  Meal_FB                        78879 non-null  uint8  \n",
      " 34  Meal_HB                        78879 non-null  uint8  \n",
      " 35  Meal_SC                        78879 non-null  uint8  \n",
      " 36  MarketSegment_Aviation         78879 non-null  uint8  \n",
      " 37  MarketSegment_Complementary    78879 non-null  uint8  \n",
      " 38  MarketSegment_Corporate        78879 non-null  uint8  \n",
      " 39  MarketSegment_Direct           78879 non-null  uint8  \n",
      " 40  MarketSegment_Groups           78879 non-null  uint8  \n",
      " 41  MarketSegment_Offline TA/TO    78879 non-null  uint8  \n",
      " 42  MarketSegment_Online TA        78879 non-null  uint8  \n",
      " 43  DistributionChannel_Corporate  78879 non-null  uint8  \n",
      " 44  DistributionChannel_Direct     78879 non-null  uint8  \n",
      " 45  DistributionChannel_GDS        78879 non-null  uint8  \n",
      " 46  DistributionChannel_TA/TO      78879 non-null  uint8  \n",
      " 47  ReservedRoomType_A             78879 non-null  uint8  \n",
      " 48  ReservedRoomType_B             78879 non-null  uint8  \n",
      " 49  ReservedRoomType_C             78879 non-null  uint8  \n",
      " 50  ReservedRoomType_D             78879 non-null  uint8  \n",
      " 51  ReservedRoomType_E             78879 non-null  uint8  \n",
      " 52  ReservedRoomType_F             78879 non-null  uint8  \n",
      " 53  ReservedRoomType_G             78879 non-null  uint8  \n",
      " 54  DepositType_No_Deposit         78879 non-null  uint8  \n",
      " 55  DepositType_Non_Refund         78879 non-null  uint8  \n",
      " 56  DepositType_Refundable         78879 non-null  uint8  \n",
      " 57  CustomerType_Contract          78879 non-null  uint8  \n",
      " 58  CustomerType_Group             78879 non-null  uint8  \n",
      " 59  CustomerType_Transient         78879 non-null  uint8  \n",
      " 60  CustomerType_Transient-Party   78879 non-null  uint8  \n",
      "dtypes: float64(1), int64(19), uint8(41)\n",
      "memory usage: 15.1 MB\n"
     ]
    }
   ],
   "source": [
    "#verificando as colunas existentes em nosso dataframe, após o preprocessamento\n",
    "df_model.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "Nossos dados já estão no formato apropriado para serem inputados no modelo.\n",
    "\n",
    "Antes do treinamento, separamos nosso conjunto de dados em conjunto de treinamento, validação e teste. Faremos um split de 60/20/20%, respectivamente.\n",
    "O objetivo do conjunto de validação é escolher o melhor entre os modelos que treinaremos. Já o conjunto de teste será usado uma única vez, ao final do projeto, para estimar a performance que nosso modelo terá em produção.\n",
    "\n",
    "Faremos um split estratificado. Ou seja, manteremos a mesma proporção de reservas canceladas em cada conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de treinamento: 47327 exemplos\n",
      "Conjunto de validação: 15776 exemplos\n",
      "Conjunto de teste: 15776 exemplos\n"
     ]
    }
   ],
   "source": [
    "#train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#separando a variável dependente e as variáveis independentes\n",
    "y = df_model.IsCanceled\n",
    "X = df_model.drop('IsCanceled', axis=1)\n",
    "\n",
    "#separando o conjunto de treinamento\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=101, stratify=y)\n",
    "\n",
    "#separando os conjuntos de teste e validação\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.50, random_state=101, stratify=y_test)\n",
    "\n",
    "#tamanho de cada conjunto:\n",
    "print(f\"Conjunto de treinamento: {X_train.shape[0]} exemplos\")\n",
    "print(f\"Conjunto de validação: {X_val.shape[0]} exemplos\")\n",
    "print(f\"Conjunto de teste: {X_test.shape[0]} exemplos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark model\n",
    "Vamos treinar um modelo com os parâmetros default do XGBoost para termos uma base de performance.\n",
    "\n",
    "Escolhemos usar a métrica da área sob a curva do ROC (auc). Isso nos dará o modelo que tem melhor trade-off entre a precisão e o recall de cancelamentos.\n",
    "\n",
    "Usando nosos conjunto de validação, interromperemos o treinamento de novos previsores (árvores) quando não observarmos melhora de auc em 30 árvores seguidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas do modelo de benchmark:\n",
      "AUC: 0.946865\n",
      "Accuracy: 87.23%\n",
      "Recall: 82.54%\n",
      "Precision: 86.37%\n",
      "f1_score: 84.41%\n"
     ]
    }
   ],
   "source": [
    "#instanciando o modelo do xgboost para benchmark\n",
    "model = XGBClassifier(n_estimators=1000)\n",
    "\n",
    "#treinando o modelo de benchmark\n",
    "model.fit(X_train, y_train, early_stopping_rounds=30, eval_set=[(X_val, y_val)], eval_metric='auc', verbose=0)\n",
    "\n",
    "#fazendo previsões no conjunto de validação com o modelo de benchmark\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "#calculando e imprimindo as métricas do modelo de benchmark\n",
    "accuracy = accuracy_score(y_val, predictions)\n",
    "recall = recall_score(y_val, predictions)\n",
    "precision = precision_score(y_val, predictions)\n",
    "f1_scoree = f1_score(y_val, predictions)\n",
    "print(\"Métricas do modelo de benchmark:\")\n",
    "print(f\"AUC: {model.evals_result()['validation_0']['auc'][-1]}\")\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
    "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
    "print(\"f1_score: %.2f%%\" % (f1_scoree * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre as reservas que foram canceladas em nosso conjunto de validação, o modelo de benchmark conseguiu prever corretamente 82.54% delas (recall).\n",
    "\n",
    "Mais abaixo, discutirei com profundidade o recall obtido pelo modelo, e tentarei otimizá-lo. Acredito que o recall tenha uma relevância grande para o projeto. Isso porque o recall mede o percentual de acertos do modelo nas reservas que são canceladas, de fato. E se o hotel sabe de antemão que uma reserva tem alta probabilidade de cancelamento, pode agir para evitar esse cancelamento (oferecendo algum benefício ao cliente, por exemplo). Isso tem um grande potencial de impacto no negócio, uma vez que, [como vimos](EDA.ipynb), 41% de todas as reservas são canceladas, em média.\n",
    "\n",
    "## Refinando o modelo\n",
    "Agora que já treinamos nosso modelo de benchmark, vamos procurar os valores dos hiperparâmetros do xgboost que otimizam nossa métrica de avaliação, o auc.\n",
    "\n",
    "A implementação do Gradient Boosting do XGBoosting possui vários parâmetros de treinamento, como por exemplo o learning_rate (coeficiente do resultado encontrado por cada árvore para o cálculo da previsão final) e max_depth (número máximo de camadas de cada árvore, que restringe a quantidade de splits que cada árvore faz). Esses parâmetros não são treináveis, i.e., devem ser informados manualmente ao algoritmo antes que ele realize o treinamento que irá determinar as especificações do modelo que fará a previsão de novos exemplos. Por isso, eles são chamados de hiperparâmetros.\n",
    "\n",
    "O processo de refinamento consiste em treinar diferentes modelos, que diferem pelos seus hiperparâmetros, e utilizar nosso conjunto de validação para verificar qual dos modelos faz a melhor previsão. Compararemos a qualidade dos modelos pela métrica do auc, conforme dito acima.\n",
    "\n",
    "As duas formas mais comuns de se testar diferentes conjuntos de hiperparâmetros são o \"grid search\" e o \"random search\". No primeiro, definimos um conjunto discreto de valores candidatos para cada hiperparâmetro, e treinamos modelos com todas as combinações possíveis entre os diferentes hiperparâmetros. No segundo, definimos intervalos de valores candidatos para cada hiperparâmetro, e selecionamos aleatoriamente, dentro de cada intervalo, os valores que serão utilizados em cada modelo.\n",
    "\n",
    "Uma terceira forma de fazer a busca por hiperparâmetros é o [Bayesian optimization](https://towardsdatascience.com/automated-machine-learning-hyperparameter-tuning-in-python-dfda59b72f8a). Nesse método, também sorteamos aleatoriamente valores para os hiperparâmetros. Mas, ao contrário do random search, onde a distribuição de probabilidades entre os valores possíveis é uniforme, o Bayesian optimization utiliza iterativamente os resultados que vão sendo obtidos para explorar mais intensamente os intervalos de valores mais promissores, para cada hiperparâmetro. Assim, a cada novo modelo treinado, é atualizada a distribuição de probabilidade dos valores associados a cada hiperparâmetro. A implementação do Bayesian optimization que utilizaremos aqui é a do pacote [hyperopt](https://github.com/hyperopt/hyperopt).\n",
    "\n",
    "Como o pacote [hyperopt](https://github.com/hyperopt/hyperopt) precisa de uma função para MINIMIZAR, vamos definí-la como 1 - auc. Assim, minimizando o auc, estamos maximizando o auc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK\n",
    "\n",
    "#definindo a função que treina o modelo e calcula a métrica de avaliação\n",
    "def objective(params):\n",
    "    \"\"\"Objective function for Gradient Boosting Machine Hyperparameter Tuning\"\"\"     \n",
    "    \n",
    "    #gerando o modelo\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=1000,\n",
    "        learning_rate = params['learning_rate'],\n",
    "        gamma = params['gamma'],\n",
    "        max_depth = params['max_depth'],\n",
    "        min_child_weight = params['min_child_weight'],\n",
    "        reg_lambda = params['reg_lambda'],\n",
    "        reg_alpha = params['reg_alpha'],\n",
    "    )\n",
    "    \n",
    "    #treinando o modelo\n",
    "    model.fit(X_train, y_train, early_stopping_rounds=30, eval_set=[(X_val, y_val)], eval_metric='auc', verbose=0)\n",
    "    \n",
    "    #métrica de avaliação: 1 - ROC AUC\n",
    "    loss = 1 - model.evals_result()['validation_0']['auc'][-1]\n",
    "    \n",
    "    # dicionário com o resultado\n",
    "    return {'loss': loss, 'params': params, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Espaço de hiperparâmetros a ser explorado\n",
    "from hyperopt import hp\n",
    "\n",
    "space = {\n",
    "#    'boosting_type': hp.choice('boosting_type', [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n",
    "#                                                 {'boosting_type': 'goss', 'subsample': 1.0}]),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.3)),\n",
    "    'gamma': hp.uniform('gamma', 0.0, 5.0),\n",
    "    'max_depth': hp.randint('max_depth', 5, 20),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', np.log(0.08), np.log(10)),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 2.0),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 2.1602457808326743,\n",
       " 'learning_rate': 0.2802196181178618,\n",
       " 'max_depth': array(16),\n",
       " 'min_child_weight': 5.920776518774782,\n",
       " 'reg_alpha': 1.289599111321481,\n",
       " 'reg_lambda': 0.43225440411094906}"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testando o espaço de hiperparâmetros: sorteando um conjunto aleatório de hiperparâmetros\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "\n",
    "example = sample(space)\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99%|████████████████████████████████████████████▋| 121/122 [00:49<00:00,  2.44trial/s, best loss: 0.04821600000000004]\n"
     ]
    }
   ],
   "source": [
    "# Treinando os primeiros 50 modelos\n",
    "\n",
    "# Algoritmo\n",
    "from hyperopt import tpe\n",
    "tpe_algorithm = tpe.suggest\n",
    "\n",
    "\n",
    "# Objeto que registra o progresso\n",
    "from hyperopt import Trials\n",
    "bayes_trials = Trials()\n",
    "\n",
    "# Função que faz a busca\n",
    "from hyperopt import fmin\n",
    "\n",
    "# Rodando a busca\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, \n",
    "            max_evals = 50, trials = bayes_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "número de modelos já treinados: 320\n"
     ]
    }
   ],
   "source": [
    "#salvando/retomando a busca do hyperopt\n",
    "\n",
    "import pickle\n",
    "#salvando a busca\n",
    "#pickle.dump(bayes_trials, open(\"hyperopt_trials.p\", \"wb\"))\n",
    "\n",
    "#carregando a busca\n",
    "bayes_trials = pickle.load(open(\"hyperopt_trials.p\", \"rb\"))\n",
    "\n",
    "#quantos trials já foram rodados?\n",
    "print(f\"número de modelos já treinados: {len(bayes_trials.losses())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████▊| 319/320 [1:31:44<00:17, 17.26s/trial, best loss: 0.047996999999999956]\n"
     ]
    }
   ],
   "source": [
    "#reiniciando a busca\n",
    "\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, \n",
    "            max_evals = 320, trials = bayes_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível salvar o resultado parcial da busca e depois retomá-la, conforme fiz acima.\n",
    "\n",
    "A busca retorna o conjunto de hiperparâmetros que otimiza a métrica de avaliação. Abaixo, treinamos o modelo com o melhor conjunto de hiperparâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc do melhor modelo: 0.952003\n"
     ]
    }
   ],
   "source": [
    "#treinando o melhor modelo\n",
    "\n",
    "params = bayes_trials.best_trial['result']['params']\n",
    "\n",
    "\n",
    "model = XGBClassifier(\n",
    "        n_estimators=1000,\n",
    "        learning_rate = params['learning_rate'],\n",
    "        gamma = params['gamma'],\n",
    "        max_depth = params['max_depth'],\n",
    "        min_child_weight = params['min_child_weight'],\n",
    "        reg_lambda = params['reg_lambda'],\n",
    "        reg_alpha = params['reg_alpha'],\n",
    "    )\n",
    "\n",
    "model.fit(X_train, y_train, early_stopping_rounds=30, eval_set=[(X_val, y_val)], eval_metric='auc', verbose=0)\n",
    "\n",
    "#printando loss do melhor modelo\n",
    "auc = 1 - model.evals_result()['validation_0']['auc'][-1]\n",
    "print(f\"auc do melhor modelo: {1-auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A busca bayesiana permitiu que refinássemos os hiperparâmetros, aumentando o auc de 0.9469 (modelo de benchmark) para 0.9520.\n",
    "\n",
    "Além disso, conforme vemos abaixo, nosso modelo refinado foi capaz de classificar corretamente 83.42% das reservas que foram canceladas em nosso conjunto de validação (recall), contra a marca de 82.54% do modelo de benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas do modelo refinado no conjunto de validação:\n",
      "Accuracy: 87.92%\n",
      "Recall: 83.42%\n",
      "Precision: 87.19%\n",
      "f1_score: 85.26%\n"
     ]
    }
   ],
   "source": [
    "#fazendo previsões no conjunto de validação com o modelo refinado\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "#calculando e imprimindo as métricas do modelo refinado\n",
    "accuracy = accuracy_score(y_val, predictions)\n",
    "recall = recall_score(y_val, predictions)\n",
    "precision = precision_score(y_val, predictions)\n",
    "f1_scoree = f1_score(y_val, predictions)\n",
    "print(\"Métricas do modelo refinado no conjunto de validação:\")\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
    "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
    "print(\"f1_score: %.2f%%\" % (f1_scoree * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliando overfitting\n",
    "Vemos abaixo que nosso modelo alcançou um f1_score de 96.62% no conjunto de treinamento, contra 85.26% no conjunto de validação. Isso aponta que nosso modelo tem um certo grau de overfitting, uma vez que sua performance é consideravelmente melhor nos pontos em que foi treinado. \n",
    "\n",
    "Para minimizar o overfitting podemos otimizar certos hiperparâmetros do XGBoosting com que ainda não trabalhamos, como o subsample. Outra estratégia para combater o problema é aumentar o tamanho de nosso conjunto de treinamento. Para isso, uma possibilidade é fazermos k-fold validation, ao invés de usar um conjunto separado para validação.\n",
    "\n",
    "Numa próxima etapa do projeto tentaremos minimizar esse overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas do modelo refinado no conjunto de treinamento:\n",
      "Accuracy: 97.18%\n",
      "Recall: 96.20%\n",
      "Precision: 97.04%\n",
      "f1_score: 96.62%\n"
     ]
    }
   ],
   "source": [
    "#fazendo previsões no conjunto de treinamento com o modelo refinado\n",
    "predictions = model.predict(X_train)\n",
    "\n",
    "#calculando e imprimindo as métricas do modelo refinado\n",
    "accuracy = accuracy_score(y_train, predictions)\n",
    "recall = recall_score(y_train, predictions)\n",
    "precision = precision_score(y_train, predictions)\n",
    "f1_scoree = f1_score(y_train, predictions)\n",
    "print(\"Métricas do modelo refinado no conjunto de treinamento:\")\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
    "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
    "print(\"f1_score: %.2f%%\" % (f1_scoree * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimizando para o Recall\n",
    "Conforme discutido acima, acredito que o recall tenha uma relevância grande para o projeto. Isso porque o recall mede o percentual de acertos do modelo nas reservas que são canceladas, de fato. E se o hotel sabe de antemão que uma reserva tem alta probabilidade de cancelamento, pode agir para evitar esse cancelamento (oferecendo algum benefício ao cliente, por exemplo). Isso tem um grande potencial de impacto no negócio, uma vez que, [como vimos](EDA.ipynb), 41% de todas as reservas são canceladas, em média.\n",
    "\n",
    "Até agora, para que nosso modelo previsse que uma reserva seria cancelada, era necessário que a probabilidade de cancelamento calculada para essa reserva chegasse a 50%. Podemos otimizar o recall diminuindo esse threshold de probabilidade. Assim, por exemplo, uma reserva com 45% de probabilidade de cancelamento já seria prevista como cancelada por nosso modelo.\n",
    "\n",
    "Temos um trade-off, no entanto. Ao diminuir esse threshold, estaremos cometendo, com mais frequência, o erro de classificar como canceladas reservas que, de fato, não seriam canceladas. O impacto desse erro para o negócio é que o hotel oferecerá, com maior frequência, algum tipo de vantagem para clientes que não iriam cancelar suas reservas.\n",
    "\n",
    "Para avaliar o trade-off, plotaremos o precision e recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fazendo as previsões da probabilidade de cancelamento no conjunto de validação\n",
    "predictions_proba = model.predict_proba(X_val)\n",
    "\n",
    "#colocando as probabilidades calculadas num dataframe\n",
    "pred_df = pd.DataFrame(predictions_proba, columns=['0', '1'])\n",
    "    \n",
    "#candidatos a thresholds\n",
    "thresholds_list = [i for i in np.arange(0.2, 0.5, 0.005)]\n",
    "    \n",
    "#dicionário para guardar os resultados\n",
    "results = {'threshold': [], 'recall': [], 'precision': [], 'f1_scoree': []}\n",
    "\n",
    "#calculando precision, recall e f1-score para diferentes thresholds e guardando o resultado num dicionário\n",
    "for threshold in thresholds_list:\n",
    "    #previsão para o threshold da vez\n",
    "    predictions = pred_df['1'].apply(lambda x: 1 if x > threshold else 0)\n",
    "    #calculando as métricas e guardando no dicionário de resultados\n",
    "    results['threshold'].append(threshold)\n",
    "    results['recall'].append(recall_score(y_val, predictions))\n",
    "    results['precision'].append(precision_score(y_val, predictions))\n",
    "    results['f1_scoree'].append(f1_score(y_val, predictions))\n",
    "    \n",
    "#plotando as métricas contra o threshold\n",
    "plt.scatter(y=results['f1_scoree'], x=results['threshold'], label='f1_score')\n",
    "plt.scatter(y=results['recall'], x=results['threshold'], label='recall')\n",
    "plt.scatter(y=results['precision'], x=results['threshold'], label='precision')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como previsto, à medida que o recall aumenta, a precision diminui. Como estamos dando mais importância ao recall, conforme explicado acima, vou escolher o threshold de 0.25. Em outras palavras, toda vez que nosso modelo calcular que a probabilidade de uma reserva ser cancelada é maior que 25%, nossa previsão será de que aquela reserva será cancelada.\n",
    "\n",
    "Como podemos ver abaixo, o threshold de 25% dá, no conjunto de validação, um recall de 92.12% e uma precision de 77.33%.\n",
    "\n",
    "Isso significa que, sempre que uma reserva vai ser cancelada pelo cliente, nosso modelo consegue prever corretamente em 92.12% dos casos. Em contrapartida, de todas as vezes que nosso modelo diz que uma reserva será cancelada, ele acerta em 77.33% das vezes. Ou seja, em 22.66% das vezes que nosso modelo diz que uma reserva será cancelada, na verdade ela não é."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas com threshold de 25% no conjunto de validação:\n",
      "Accuracy: 49.84%\n",
      "Recall: 49.55%\n",
      "Precision: 41.69%\n",
      "f1_score: 45.28%\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.25\n",
    "\n",
    "pred_df[\"final_pred\"] = pred_df['1'].apply(lambda x: 1 if x > threshold else 0)\n",
    "\n",
    "#fazendo previsões no conjunto de validação com o modelo refinado\n",
    "predictions = pred_df[\"final_pred\"]\n",
    "\n",
    "#calculando e imprimindo as métricas do modelo refinado\n",
    "accuracy = accuracy_score(y_val, predictions)\n",
    "recall = recall_score(y_val, predictions)\n",
    "precision = precision_score(y_val, predictions)\n",
    "f1_scoree = f1_score(y_val, predictions)\n",
    "print(\"Métricas com threshold de 25% no conjunto de validação:\")\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
    "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
    "print(\"f1_score: %.2f%%\" % (f1_scoree * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimando a acurácia do modelo em produção\n",
    "Para estimar o desempenho do nosso modelo em produção, vamos utilizar o conjunto de teste. Perceba que essa é a primeira vez que utilizamos o conjunto de teste na modelagem. Isso garante que nenhum hiperparâmetro foi selecionado para otimizar o modelo para esse conjunto.\n",
    "\n",
    "Os pontos que temos no conjunto de teste nunca foram vistos pelo modelo, de modo que seu desempenho nesse conjunto é uma medida mais acurada do desempenho que o modelo terá no mundo real, em produção.\n",
    "\n",
    "Vemos abaixo que o modelo teve um desempenho no conjunto de teste muito próximo daquele observado no conjunto de validação. Isso significa que nosso modelo generaliza bem para pontos inéditos, e nos dá maior confiança de usá-lo em produção.\n",
    "\n",
    "A estimativa final é que nosso consegue prever corretamente 92.03% das reservas que serão canceladas. Ao mesmo tempo, 22.56% das vezes que nosso modelo diz que uma reserva será cancelada, ele erra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas no conjunto de teste:\n",
      "Accuracy: 85.43%\n",
      "Recall: 92.03%\n",
      "Precision: 77.44%\n",
      "f1_score: 84.11%\n"
     ]
    }
   ],
   "source": [
    "#test set\n",
    "\n",
    "predictions_proba = model.predict_proba(X_test)\n",
    "\n",
    "pred_df = pd.DataFrame(predictions_proba, columns=['0', '1'])\n",
    "\n",
    "threshold = 0.25\n",
    "\n",
    "pred_df[\"final_pred\"] = pred_df['1'].apply(lambda x: 1 if x > threshold else 0)\n",
    "\n",
    "#fazendo previsões no conjunto de validação com o modelo refinado\n",
    "predictions = pred_df[\"final_pred\"]\n",
    "\n",
    "#calculando e imprimindo as métricas do modelo refinado\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions)\n",
    "f1_scoree = f1_score(y_test, predictions)\n",
    "print(\"Métricas no conjunto de teste:\")\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print(\"Recall: %.2f%%\" % (recall * 100.0))\n",
    "print(\"Precision: %.2f%%\" % (precision * 100.0))\n",
    "print(\"f1_score: %.2f%%\" % (f1_scoree * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgboost_model.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#salvando o modelo\n",
    "from joblib import dump\n",
    "\n",
    "dump(model, 'xgboost_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvando o X_train\n",
    "X_train.to_csv('X_train.csv', index=False)\n",
    "\n",
    "y_train.to_csv('y_train.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
